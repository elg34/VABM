{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The settings passed to the model functions still take settings as an argument string, so could easily be called from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import seaborn as sns\n",
    "\n",
    "import helpers # this is where the main training/decoding functions are, modified from teh original HIVAE main.py\n",
    "\n",
    "#import warnings \n",
    "#warnings.filterwarnings('ignore') ########## NOTE: comment out for testing in case it's hiding problems\n",
    "\n",
    "def set_settings(opts,nepochs=500,modload=False,save=True): # note: modload doesnt do anything right now, hardcoded in helpers.py\n",
    "    'replace setting template placeholders with file info'\n",
    "    inputf=re.sub('.csv','',opts['files'].iloc[0])\n",
    "    missf=inputf+'_missing.csv'\n",
    "    typef=inputf+'_types.csv'\n",
    "    \n",
    "    template = '--epochs NEPOCHS --model_name model_HIVAE_inputDropout --restore MODLOAD \\\n",
    "        --data_file data_python/INPUT_FILE.csv --types_file data_python/TYPES_FILE \\\n",
    "         --batch_size NBATCH --save NEPFILL --save_file SAVE_FILE\\\n",
    "        --dim_latent_s SDIM --dim_latent_z 1 --dim_latent_y YDIM \\\n",
    "        --miss_percentage_train 0 --miss_percentage_test 0 \\\n",
    "        --true_miss_file data_python/MISS_FILE --learning_rate LRATE'\n",
    "    \n",
    "    # replace placeholders in template\n",
    "    settings = re.sub('INPUT_FILE',inputf,template)\n",
    "    settings = re.sub('NBATCH',str(opts['nbatch'].iloc[0]),settings)\n",
    "    settings = re.sub('NEPOCHS',str(nepochs),settings)\n",
    "    settings = re.sub('NEPFILL',str(nepochs-1),settings) if save else re.sub('NEPFILL',str(nepochs*2),settings)\n",
    "    settings = re.sub('YDIM',str(opts['ydims'].iloc[0]),settings)\n",
    "    settings = re.sub('SDIM',str(opts['sdims'].iloc[0]),settings)\n",
    "    settings = re.sub('MISS_FILE',missf,settings) if not 'medhist' in inputf else re.sub('--true_miss_file data_python/MISS_FILE','',settings)\n",
    "    settings = re.sub('TYPES_FILE',typef,settings)\n",
    "    settings = re.sub('SAVE_FILE',inputf,settings)\n",
    "    settings = re.sub('LRATE',str(opts['lrates'].iloc[0]),settings)\n",
    "    settings = re.sub('MODLOAD','1',settings) if modload else re.sub('MODLOAD','0',settings)\n",
    "    \n",
    "    return settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experience it is sufficient to leave the s-code dimensions at 1 in most cases, unless the reconstruction error or the shape of the zcode distribution is concerning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=362\n",
    "# get file list\n",
    "files=[i for i in os.listdir('data_python/') if not '_type' in i and not '_missing' in i]\n",
    "sds=[1]*20 + [2] + [1]*13\n",
    "sdims=dict(zip(files,sds))\n",
    "best_hyper=pd.read_csv('results_PPMI.csv')\n",
    "best_hyper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training, then check \"Saved Networks/train_stats/\" for images of the reconstruction loss over the epochs. If training didnt converge for some files, rerun individual files below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    opts=dict(best_hyper[best_hyper['files'].copy()==f])\n",
    "    settings=set_settings(opts,modload=False,save=True)\n",
    "    helpers.train_network(settings)\n",
    "wave = np.sin(2*np.pi*400*np.arange(10000*2)/10000)\n",
    "Audio(wave, rate=10000, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If training didnt converge for some files, rerun individual files below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files[24:25]:\n",
    "    opts=dict(best_hyper[best_hyper['files'].copy()==f])\n",
    "    settings=set_settings(opts,modload=False,save=True)\n",
    "    helpers.train_network(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves out the embeddings for use in the Bayesian Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=list()\n",
    "dfs=list()\n",
    "for f in files:\n",
    "    # replace placeholders in template\n",
    "    opts=dict(best_hyper[best_hyper['files'].copy()==f])\n",
    "    opts['nbatch'].iloc[0]=sample_size\n",
    "    settings=set_settings(opts,nepochs=1,modload=True,save=False)\n",
    "    \n",
    "    #run\n",
    "    encs,encz,d=helpers.enc_network(settings)\n",
    "\n",
    "    # make deterministic embeddings\n",
    "    subj=pd.read_csv('python_names/'+re.sub('.csv','',f)+'_subj.csv')['x']\n",
    "    sc=pd.DataFrame({'scode_'+re.sub('.csv','',f):pd.Series(np.array([i for i in encs])),'SUBJID':subj})\n",
    "    zc=pd.DataFrame({'zcode_'+re.sub('.csv','',f):pd.Series(np.array([i[0] for i in encz])),'SUBJID':subj})\n",
    "    enc=pd.merge(sc, zc, on = 'SUBJID')\n",
    "    \n",
    "    # save out individual file's metadata\n",
    "    enc.to_csv('Saved_Networks/'+re.sub('.csv','',f)+'_meta.csv',index = False)\n",
    "    dfs.append(enc)\n",
    "    dat.append(d)\n",
    "\n",
    "# join metadata\n",
    "enc_vars=[pd.read_csv('Saved_Networks/'+re.sub('.csv','',f)+'_meta.csv') for f in files]\n",
    "meta=helpers.merge_dat(enc_vars)\n",
    "meta[meta.columns[['Unnamed' not in i for i in meta.columns]]].to_csv('metaenc.csv',index= False)\n",
    "\n",
    "dat_dic=dict(zip(files,dat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting embedding distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = scatter_matrix(\n",
    "    meta[meta.columns.drop(list(meta.filter(regex='SUBJID|scode_')))],\n",
    "    figsize  = [15, 15],\n",
    "    marker   = \".\",\n",
    "    s        = 10,\n",
    "    diagonal = \"kde\"\n",
    ")\n",
    "for ax in fig.ravel():\n",
    "    ax.set_xlabel(re.sub('_VIS|zcode_','',ax.get_xlabel()), fontsize = 20, rotation = 90)\n",
    "    ax.set_ylabel(re.sub('_VIS|zcode_','',ax.get_ylabel()), fontsize = 20, rotation = 90)\n",
    "    \n",
    "plt.suptitle('HI-VAE embeddings (deterministic)',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for plotting the marginal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('metaenc.csv')\n",
    "\n",
    "recon=list()\n",
    "recdfs=list()\n",
    "for f in files:\n",
    "    # replace placeholders in template\n",
    "    opts=dict(best_hyper[best_hyper['files'].copy()==f])\n",
    "    opts['nbatch'].iloc[0]=sample_size\n",
    "    settings=set_settings(opts,nepochs=1,modload=True,save=False)\n",
    "    \n",
    "    #run\n",
    "    zcodes=meta['zcode_'+re.sub('.csv','',f)]\n",
    "    scodes=meta['scode_'+re.sub('.csv','',f)]\n",
    "    rec=helpers.dec_network(settings,zcodes,scodes)\n",
    "    recon.append(rec)\n",
    "    \n",
    "    subj=pd.read_csv('python_names/'+re.sub('.csv','',f)+'_subj.csv')['x']\n",
    "    names=pd.read_csv('python_names/'+re.sub('.csv','',f)+'_cols.csv')['x']\n",
    "    recd=pd.DataFrame(rec)\n",
    "    recd.columns=names\n",
    "    recd['SUBJID']=subj\n",
    "    recdfs.append(recd)\n",
    "    \n",
    "recon_dic=dict(zip(files,recon))\n",
    "\n",
    "data_recon=helpers.merge_dat(recdfs)\n",
    "data_recon.to_csv('reconRP.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Loglikelihoods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('metaenc.csv')\n",
    "\n",
    "dfs=list()\n",
    "for f in files:\n",
    "    # replace placeholders in template\n",
    "    opts=dict(best_hyper[best_hyper['files'].copy()==f])\n",
    "    opts['nbatch'].iloc[0]=sample_size\n",
    "    settings=set_settings(opts,nepochs=1,modload=True,save=False)\n",
    "    \n",
    "    #run\n",
    "    zcodes=meta['zcode_'+re.sub('.csv','',f)]\n",
    "    scodes=meta['scode_'+re.sub('.csv','',f)]\n",
    "    \n",
    "    loglik=helpers.dec_network_loglik(settings,zcodes,scodes)\n",
    "    loglik=np.nanmean(np.array(loglik).T,axis=1)\n",
    "    subj=pd.read_csv('python_names/'+re.sub('.csv','',f)+'_subj.csv')['x']\n",
    "    dat=pd.DataFrame(loglik)\n",
    "    dat.columns=[f]\n",
    "    dat['SUBJID']=subj\n",
    "    dfs.append(dat)\n",
    "\n",
    "decoded=helpers.merge_dat(dfs)\n",
    "decoded.to_csv('training_logliks.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
