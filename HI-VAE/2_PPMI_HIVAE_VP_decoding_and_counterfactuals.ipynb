{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import seaborn as sns\n",
    "\n",
    "import helpers # this is where the main training/decoding functions are, modified from teh original HIVAE main.py\n",
    "\n",
    "#import warnings \n",
    "#warnings.filterwarnings('ignore') ########## NOTE: comment out for testing in case it's hiding problems\n",
    "\n",
    "def set_settings(opts,nepochs=500,modload=False,save=True): # note: modload doesnt do anything right now, hardcoded in helpers.py\n",
    "    'replace setting template placeholders with file info'\n",
    "    inputf=re.sub('.csv','',opts['files'].iloc[0])\n",
    "    missf=inputf+'_missing.csv'\n",
    "    typef=inputf+'_types.csv'\n",
    "    \n",
    "    template = '--epochs NEPOCHS --model_name model_HIVAE_inputDropout --restore MODLOAD \\\n",
    "        --data_file data_python/INPUT_FILE.csv --types_file data_python/TYPES_FILE \\\n",
    "         --batch_size NBATCH --save NEPFILL --save_file SAVE_FILE\\\n",
    "        --dim_latent_s SDIM --dim_latent_z 1 --dim_latent_y YDIM \\\n",
    "        --miss_percentage_train 0 --miss_percentage_test 0 \\\n",
    "        --true_miss_file data_python/MISS_FILE --learning_rate LRATE'\n",
    "    \n",
    "    # replace placeholders in template\n",
    "    settings = re.sub('INPUT_FILE',inputf,template)\n",
    "    settings = re.sub('NBATCH',str(opts['nbatch'].iloc[0]),settings)\n",
    "    settings = re.sub('NEPOCHS',str(nepochs),settings)\n",
    "    settings = re.sub('NEPFILL',str(nepochs-1),settings) if save else re.sub('NEPFILL',str(nepochs*2),settings)\n",
    "    settings = re.sub('YDIM',str(opts['ydims'].iloc[0]),settings)\n",
    "    settings = re.sub('SDIM',str(opts['sdims'].iloc[0]),settings)\n",
    "    settings = re.sub('MISS_FILE',missf,settings) if not 'medhist' in inputf else re.sub('--true_miss_file data_python/MISS_FILE','',settings)\n",
    "    settings = re.sub('TYPES_FILE',typef,settings)\n",
    "    settings = re.sub('SAVE_FILE',inputf,settings)\n",
    "    settings = re.sub('LRATE',str(opts['lrates'].iloc[0]),settings)\n",
    "    settings = re.sub('MODLOAD','1',settings) if modload else re.sub('MODLOAD','0',settings)\n",
    "    \n",
    "    return settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=362\n",
    "# get file list\n",
    "files=[i for i in os.listdir('data_python/') if not '_type' in i and not '_missing' in i]\n",
    "sds=[1]*20 + [2] + [1]*13\n",
    "sdims=dict(zip(files,sds))\n",
    "best_hyper=pd.read_csv('results_PPMI.csv')\n",
    "if any(files!=best_hyper['files']):\n",
    "    print('ERROR!!')\n",
    "else:\n",
    "    best_hyper['sdims']=sds\n",
    "best_hyper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VP decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run after bnet.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VPcodes = ### path to virtual patient codes\n",
    "\n",
    "dfs=list()\n",
    "virt=list()\n",
    "for f in files:\n",
    "    # replace placeholders in template\n",
    "    opts=dict(best_hyper[best_hyper['files'].copy()==f])\n",
    "    opts['nbatch'].iloc[0]=sample_size\n",
    "    settings=set_settings(opts,nepochs=1,modload=True,save=False)\n",
    "    \n",
    "    #run\n",
    "    zcodes=VPcodes['zcode_'+re.sub('.csv','',f)]\n",
    "    scodes=VPcodes['scode_'+re.sub('.csv','',f)] if 'scode_'+re.sub('.csv','',f) in VPcodes.columns else np.zeros(zcodes.shape)\n",
    "        \n",
    "    dec=helpers.dec_network(settings,zcodes,scodes,VP=True)\n",
    "    subj=pd.read_csv('python_names/'+re.sub('.csv','',f)+'_subj.csv')['x']\n",
    "    names=pd.read_csv('python_names/'+re.sub('.csv','',f)+'_cols.csv')['x']\n",
    "    dat=pd.DataFrame(dec)\n",
    "    dat.columns=names\n",
    "    dat['SUBJID']=subj\n",
    "    virt.append(dec)\n",
    "    dfs.append(dat)\n",
    "\n",
    "virt_dic=dict(zip(files,virt))\n",
    "decoded=helpers.merge_dat(dfs)\n",
    "decoded.to_csv('decodedVP.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Loglikelihoods for R plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VPcodes = ### path to virtual patient codes\n",
    "dfs=list()\n",
    "for f in files:\n",
    "    # replace placeholders in template\n",
    "    opts=dict(best_hyper[best_hyper['files'].copy()==f])\n",
    "    opts['nbatch'].iloc[0]=sample_size\n",
    "    settings=set_settings(opts,nepochs=1,modload=True,save=False)\n",
    "    \n",
    "    #run\n",
    "    zcodes=VPcodes['zcode_'+re.sub('.csv','',f)]\n",
    "    scodes=VPcodes['scode_'+re.sub('.csv','',f)] if 'scode_'+re.sub('.csv','',f) in VPcodes.columns else np.zeros(zcodes.shape)\n",
    "        \n",
    "    loglik=helpers.dec_network_loglik(settings,zcodes,scodes,VP=True)\n",
    "    loglik=np.nanmean(np.array(loglik).T,axis=1)\n",
    "    subj=pd.read_csv('python_names/'+re.sub('.csv','',f)+'_subj.csv')['x']\n",
    "    dat=pd.DataFrame(loglik)\n",
    "    dat.columns=[f]\n",
    "    dat['SUBJID']=subj\n",
    "    dfs.append(dat)\n",
    "\n",
    "decoded=helpers.merge_dat(dfs)\n",
    "decoded.to_csv('virtual_logliks.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run counteractuals_bnlearn.R before running this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age on UPDRS - decoded in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "f='UPDRS_VIS00.csv'\n",
    "VPcodes = pd.read_csv('../../data/data_out/counter_updrs_age.csv')\n",
    "# replace placeholders in template\n",
    "opts=dict(best_hyper[best_hyper['files'].copy()==f])\n",
    "opts['nbatch'].iloc[0]=sample_size\n",
    "settings=set_settings(opts,nepochs=1,modload=True,save=False)\n",
    "\n",
    "#run\n",
    "zcodes=VPcodes['dv']\n",
    "scodes=np.zeros(zcodes.shape)\n",
    "\n",
    "decs=list()\n",
    "n=362\n",
    "for i in range(int(len(VPcodes['dv'])/n)):\n",
    "    dec=helpers.dec_network(settings,zcodes[i*n:(i*n+n)],scodes[i*n:(i*n+n)],VP='nomiss');\n",
    "    decs.append(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=pd.read_csv('python_names/UPDRS_VIS00_cols.csv')['x']\n",
    "allPT=pd.DataFrame(np.vstack(decs))\n",
    "allPT.columns=names\n",
    "allPT['Intervention']=VPcodes['level']\n",
    "dfm = allPT.melt(var_name='columns',id_vars='Intervention')\n",
    "g = sns.FacetGrid(dfm, col='columns',hue='Intervention',col_wrap=3,sharex=False, sharey=False)\n",
    "g = (g.map(sns.distplot, 'value')).add_legend()\n",
    "allPT.to_csv('CF_output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ['No intervention', 'Age -20yrs', 'Age +20yrs']\n",
    "\n",
    "for group in group:\n",
    "    subset = allPT[allPT['Intervention'] == group]\n",
    "    sns.distplot(subset['UPDRS_UPDRS_VIS00'], hist = True, kde = True,label=group)\n",
    "    \n",
    "plt.legend(title = 'Intervention')\n",
    "plt.xlabel('UPDRS total')\n",
    "plt.ylabel('Density')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
